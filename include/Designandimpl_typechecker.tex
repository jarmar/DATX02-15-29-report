\section{Type system}
%Doesn't just check, it infers
\label{sec:dai_tc}



Hopper's type checker was designed to provide compile-time guarantees about program behavior on Erlang's virtual machine. To do this it uses a variant of the Hindley-Milner \cite{TypeSchemes} \gls{typesystem} upon which Haskell's system was initially based. While making Hopper's type system as powerful as Haskell's is today is beyond the scope of this project, Hindley-Milner still allows one to write useful typed programs. For example, one can define \glslink{polymorph}{polymorphic data types} and functions. To illustrate, figure~\ref{lst:tc_map} shows a definition of lists and the mapping function over it. 

\begin{figure}[!htb]
\centering
\begin{minipage}[b]{0.68\linewidth}
\centering
\begin{lstlisting}
data List a = Cons a (List a) | Nil

map f (Cons x xs) = Cons (f x) (map f xs)
map _  _          = Nil
\end{lstlisting}
\end{minipage}
\caption{Definition of a list data type and the map function}
\label{lst:tc_map}
\end{figure}

The type for map is inferred; in general, type signatures do not need to be given to functions.

\subsection{Implementation}

The type checking module is based on the standard algorithm for \glslink{hmtypesystem}{Hindley-Milner type checking}, \Gls{algow}. It works by taking a list of definitions as input: tuples of a name, a syntax tree that represents the value the name is defined to be and an optional type signature. The type checker then divides the definitions into those which have type signatures and those that do not. Definitions without signatures are further divided into groups of mutually recursive definitions. Those groups are \glspl{scc} in the functions' dependency graph. A dependency graph is a directed graph with names as nodes; if the definition of a value \texttt{n1} refers to \texttt{n2} then there is an edge from \texttt{n1} to \texttt{n2} in the graph. For example, in the module shown in figure~\ref{lst:tc_impl}, \texttt{noTypeSig} will be divided into its own group of mutually recursive values, \texttt{mutual1} and \texttt{mutual2} will be in the same and \texttt{withTypeSig} will be treated separately. 

\begin{figure}[!htb]
\centering
\begin{minipage}[b]{0.55\linewidth}
\centering
\begin{lstlisting}
module Example where
noTypeSig = 3
mutual1 = mutual2
mutual2 = mutual1
withTypeSig :: String
withTypeSig = "I'm well typed!"
\end{lstlisting}
\end{minipage}
\caption{Example module with mutually recursive components}
\label{lst:tc_impl}
\end{figure}

Once the definitions have been grouped, the next step is to infer the types of the definitions without type signatures. The mutually recursive groups are \glslink{topsort}{topologically sorted} by dependency. Therefore any \gls{scc} \texttt{A} which depends on another \gls{scc} \texttt{B} already having been inferred is type checked after \texttt{B}. 

%Until this point all the program has done is simple list manipulation - grouping definitions according to their dependency. In order to type check syntax trees a map between names and types and a map between type variables and types are needed. 
When a group of definitions \texttt{(f1 = e1;f2 = e2 ... fn = en)} is type checked and inferred, each name \texttt{(f1 ... fn)} is associated with a type variable. The type of each expression \texttt{(e1 ... en)} is inferred by following a number of inference rules. In Figure~\ref{eq:app} such a rule is displayed. The example shows the mathematical notation for when a lambda expression of type \texttt{$\tau \rightarrow \tau'$} is applied to a value of type \texttt{$\tau$}. This yields a new value of type \texttt{$\tau'$}.

\begin{figure}[!h]
\[
 \displaystyle\frac{\Gamma \vdash e_0:\tau \rightarrow \tau' \quad\quad \Gamma \vdash e_1 : \tau }{\Gamma \vdash e_0\ e_1 : \tau'}
\]
\caption{The application inference rule}
\label{eq:app}
\end{figure}

These rules generate a number of equations over type variables, for example \texttt{t = a -> a, List a = List Bool}, which are solved via a process called \gls{unification}. This process converts such systems to a \gls{constraint}. A constraint is a system of equations where every left-hand side is a type variable. 

Unification of two types is done by traversing both values and applying a rule for each form the type takes. For example, when unifying two type constructors (such as \texttt{Bool} and \texttt{List}) they are checked for equality. If they are not equal, unification fails. When unifying a type variable \texttt{t} with another type \texttt{$\tau$}, the algorithm checks whether \texttt{$\tau$} mentions \texttt{t}. If it does (and the type isn't just \texttt{t}) then \texttt{t} is an infinite type, which is not acceptable in Hindley-Milner. Otherwise, the equation \texttt{t = $\tau$} is added to the constraint and type variables in the right hand side of every equation are expanded as far as possible. When unifying \texttt{($\tau_1$ $\tau_2$)} and \texttt{($\tau_3$ $\tau_4$)}, the pairs \texttt{($\tau_1$, $\tau_3$)} and \texttt{($\tau_2$, $\tau_4$)} are recursively unified.  In the example \texttt{t = a -> a, List a = List Bool}, the solution would be \texttt{t = Bool -> Bool, a = Bool}. Examples of equations with no solution are \texttt{Int = Bool} and \texttt{t = List t}, which would generate an infinite type. 

The type checker remembers the constraint and successively adds more information to it with every unification.
When the types of \texttt{(f1 ... fn)} have been inferred to be of types \texttt{(t1 ... tn)}, the named values \texttt{(f1 ... fn)} will be assumed to be of those types during the rest of the type checking process. Once all \glspl{scc} have had their types inferred, the definitions with type signatures have their types inferred and unified with their signatures. If at any point in the type checking process a \gls{unification} fails, the type checker fails with an error message.

%\subsection{Implicit type arguments}

%\todo{Describe how this is done!}

%The \gls{hmtypesystem} supports qualified \gls{polymorph}, which allows one to define functions such as \texttt{reverse :: List a -> List a} and \texttt{id :: a -> a} and have them work for any type \texttt{a}. The actual runtime value of \texttt{id} or \texttt{reverse} doesn't vary based on the type. However, there is another kind of polymorphism called ad-hoc \gls{polymorph} that allows functions to vary at runtime depending on the specific type they are given. Hopper does this by implicitly passing type arguments.

%Behöver förklara vad det betyder!
%If a polymorphic Hopper function is given a type signature \texttt{Implict <type A> -> <type B>} (e.g. \texttt{Implicit a -> (a -> a -> a)}) then when it is used with a monomorphic type (e.g. type B = \texttt{Int -> Int -> Int}, leading to the constraint \texttt{a = Int}) then a data structure representing type A  = \texttt{Int} is automatically passed to the function. This makes it possible to write functions that inspect their own type at runtime. An example is \texttt{typeOf :: Implicit t -> t -> Type; typeOf t \_ = t} which returns the type of its argument.


%The Haskell function \texttt{sum :: Num a => [a] -> a} is an example of an ad-hoc-polymorphic value. It implicitly takes a method dictionary (a data structure containing numeric operations for the type \texttt{a}) as an argument and uses it to add up all the elements in the list. 


%Ad-hoc polymorphism is essential for typesafe message passing: for a Hopper process to be able to %distinguish between receiving two values of different type but with the same runtime representation (e.g. Nil :: List Number and Nil :: List Bool), the type of the value needs to be included in the message at runtime. Defining a send function to take the type of the message as an implicit type argument makes that possible. \\

%Where to put this figure? \\
%data T2 t m = T2 t m \\
%--the type, message pair that receive expects \\
%send :: Implicit t -> Pid -> t -> IO t \\
%send typ pid x = mkIO (\textbackslash \_ -> Prim.apply "erlang" "!" 2 pid (T2 typ x)) \\

\subsection{Algebraic data types and constructors}

The arity of a constructor depends on its type. For example, \texttt{Cons :: a -> List a -> List a} has arity 2. That means that a constructor's runtime representation is dependent on its type.
To simplify the code generation step the conversion from type signature to function definition is done by the type checker. This means that the code generator does not have to handle \glspl{adt}. 

In Hopper, \glspl{adt} are implemented and translated to Core Erlang in two primary cases: when they are used, and when they are declared. The implementation drew inspiration from the book \textit{Implementing functional languages: a tutorial} \cite{FunTutorial}, which describes an approach to this problem where the values of \glspl{adt} are translated to tuples, holding the constructors (represented by unique integer values) as a tag, and their additional values. \Glspl{adt} in Hopper are translated in the same manner, but translates the constructors to atoms instead to mimic the conventional structure of data in Erlang. Declared constructors are translated to functions that take a number of parameters and returns a tuple containing the constructor name and the arguments. Figures \ref{lst:hopperAdt} and \ref{lst:coreAdt} displays how \glspl{adt} values are translated from Hopper to Core Erlang.

\begin{figure}[!htb]
\centering
\begin{lstlisting} 
data Tree = Tree Number Tree Tree | Empty

Tree 5 (Tree 3 (Tree 1 Empty Empty) 
               (Tree 4 Empty Empty)) 
       (Tree 7 Empty Empty)
\end{lstlisting}
\caption{Hopper ADT with example value}
\label{lst:hopperAdt}
\end{figure}

\begin{figure}[!htb]
\centering
\begin{lstlisting} 
{'tree', 5, {'tree', 3, {'tree', 1, 'empty', 'empty'},
                        {'tree', 4, 'empty', 'empty'}},
            {'tree', 7, 'empty', 'empty'}}
\end{lstlisting}
\caption[Runtime representation of an \gls{adt} value]
 {Runtime representation of the Hopper \gls{adt} seen in figure \ref{lst:hopperAdt}}
\label{lst:coreAdt}
\end{figure}

%\todo{Add description of receive (which oppositionsgrupp wanted)}
%\todo{Maybe mention Prim.apply in passing}

%\section{Prim.apply} : Experimental feature

%To access Erlang bifs, a special function Prim.apply :: String -> String -> Number -> a has had its type hardcoded into the type checker. Prim.apply is defined in the Erlang module Prim.erl and takes a module name, a function name and an arity and returns the requisite function. For example, addition can be defined by: \\
%add :: Number -> Number -> Number
%add = Prim.apply "erlang" "+" 2 


%The following features were added at the last minute and are not officially part of Hopper. Their %syntax and semantics are not representative of production-ready Hopper should such a product ever %see the light of day; indeed, their design was largely decided by circumstance. However, the power %they add to the language justifies their inclusion in this report.

%subsubsection{Receive clauses} : Has been experimented with and there are signs of a positive future for this feature

%A central part of Erlang is the sending and receiving of messages. Erlang has primitive support for a so-called receive clause, which pattern matches on a process' mailbox until a specified waiting period has passed or until it finds a match. For example, \\
%receive true -> io:format("Received true!"); \\
%        \{X,Y\} -> io:format("Received a pair!")\\
%        after 3000 -> error(got\_nothing) end\\
%waits for three seconds to receive either 'true' or a pair before crashing. The ability to pattern match on incoming messages is a powerful feature; without it, message handling becomes much more verbose. Since there is no support for receive clauses in the parser, (how to write this? passive tone?) I transformed \\ \\
%case receive of \\
%    pattern1 -> expr \\
%    pattern1 -> expr2 \\
%    ... \\
%    After timeOut -> exprTimeOut \\ \\
%into a receive clause in the typechecker. Typesafe receive expects values to be sent in a pair along with their type. For interoperability with Erlang, non-typesafe receive is also available with the syntax \\ \\
%case unsafeReceive of \\
%    pattern1 -> expr \\
%    ... \\
%    After timeOut -> exprTimeOut \\

%To reflect the fact that they are impure, both forms of receive are of the type IO a, where a is the type of expr on the right-hand side of the case clauses.

%\subsection{In short...}

%Hopper's type system allows for polymorphic data types such as List and IO and polymorphic functions on them, typesafe message passing through send and receive, as well as a form of typeclasses. %Jag borde kunna skriva dessa exempel, beror på hur många buggar som poppar upp

%What do we do in TC/Convert?\

%•	Implement constructors (thus allowing codegen to have no knowledge of types)
%•	Give some functions implicit type arguments : abused syntax to achieve this. In some ways more powerful than Haskell’s class system (because it is done at runtime in normal Hopper), but more boilerplatey and performance intensive. Allowing values to vary based on their type (i.e. ad-hoc-polymorphism, where polymorphic values are more than just a black box, see Theorems for Free [reference?]) is essential for implementing typesafe message passing, because type information must be sent in messages at runtime to distinguish between values with same runtime representation but different types (e.g. an empty list of Booleans and an empty list of numbers).
%•	Implemented receive: abused syntax using case receive of ... -> ...
%•	A module that Converts to/from AST.AST. This is bad and is purely technical debt. Why it was created and maintained (two different ASTs, inertia, poor coordination) can be elaborated on in Discussion.
%•	Prim.apply\

%What can we do with the type system?\

%•	Higher order functions, a lot of that Haskelly goodness.
%•	IO, other types which describe processes and the connections between them. Because the BEAM is a high level VM designed for a dynamic programming language, coercing between types in Hopper does not have the same catastrophic consequences as in Haskell (which compiles to native machine code: coercing something on the heap can lead to a fatal crash e.g. because you treat a number as a pointer). That means it is rather comfortable to treat the same value as several different types in Hopper: for example a Number may be both a Natural and a Prime. We do not yet know where that leads, but it seems exciting. 



%Hopper uses the Damas-Hindley-Milner (HM) type system for the lambda calculus. HM has parametric polymorphism enabling (wording, what do I mean and what does this say???) type inference of type schemes - types with generic, quantified type variables. Further HM has the Algorithm W which not only infers the most general type for expressions but also has existing soundess and completeness proofs. These proofs means that for our well formed expressions we will always find a type and that it will be the correct type.

%\subsection{Preprocessing}

%Damas-Hindley-Milner is a type system for the lambda calculus and the parsed Hopper code has a different representation. The parsed code is transformed into an AST and the expressions written in Hopper is turned into semantically equivalent expressions in the lambda calculus. Hopper type inference is done on a simple language which is lambda calculus extended with let expressions and the fixpoint combinator. Lambda calculus in itself is Church-Turing complete and could thus represent these added constructs but they simplify ... (add stuff here)

%\begin{description}
%\item[The simple language] \hfill
%\begin{description}
%  \item[Variables] \hfill \\
%    A variable is an expression.\\
%    Ex. x is a valid expression.
%   \item[Abstraction] \hfill \\
%    An abstraction of a variable over some expression. (wording?)\\
%    Ex. (\textbackslash x . x) is a valid expression.
%   \item[Application] \hfill \\
%    An application of an expression to another expression is an expression.\\
%    Ex. (f x) is a valid expression.
%   \item[Extensions] \hfill
%\begin{description}
%    \item[Let] \hfill \\
%      A let expression, defining a variable within the scope\\
%      of an expression, is an expression.\\
%      Ex. (let x = n in (f x)) is a valid expression. 
%    \item[Fix] \hfill \\
%      The fixpoint combinator enables recursive expressions.\\
%      A fixpoint combinator y satisfies y f = f (y f).
%\end{description}
%\end{description}
%\end{description}

%\subsection{Type inference with Algorithm W}

%Where the original Algorithm W uses a top-down approach we have chosen to implement it using a bottom-up approach (sometimes called Algorithm M REF: generalizing hindley-milner type inference algorithms, Heeren,Hage,Swierstra ). The bottom-up approach generates constraints on the types in a first pass and then solves these constraints producing the most general type for each expression.

%\begin{description}
%  \item[Generating constraints by inference rules] \hfill \\
%A first pass generates constraints on the types by a set of inference rules (see appendix). \todo{FILL OUT}
%  \item[Solving constraints by solving rules] \hfill \\
%Secondly we solve the inferred types using the accumulated constraints to produce the most general type for each expression. \todo{FILL OUT}
%\end{description}
